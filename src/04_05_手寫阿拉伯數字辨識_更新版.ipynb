{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 手寫阿拉伯數字辨識 完整版"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 載入套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 設定參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_DATASETS = \"\" # 預設路徑\n",
    "BATCH_SIZE = 1024  # 批量\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟1：載入 MNIST 手寫阿拉伯數字資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28]) torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# 下載 MNIST 手寫阿拉伯數字 訓練資料\n",
    "train_ds = MNIST(PATH_DATASETS, train=True, download=True, \n",
    "                 transform=transforms.ToTensor())\n",
    "\n",
    "# 下載測試資料\n",
    "test_ds = MNIST(PATH_DATASETS, train=False, download=True, \n",
    "                 transform=transforms.ToTensor())\n",
    "\n",
    "# 訓練/測試資料的維度\n",
    "print(train_ds.data.shape, test_ds.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟2：資料探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 28, 28]), torch.Size([60000]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.data.shape, train_ds.targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 訓練資料前10筆圖片的數字\n",
    "train_ds.targets[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,  18,\n",
       "          18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170, 253,\n",
       "         253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253, 253,\n",
       "         253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253, 253,\n",
       "         198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253, 205,\n",
       "          11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,  90,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253, 190,\n",
       "           2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190, 253,\n",
       "          70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35, 241,\n",
       "         225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  81,\n",
       "         240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39, 148,\n",
       "         229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221, 253,\n",
       "         253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253, 253,\n",
       "         253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253, 195,\n",
       "          80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,  11,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "        [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0]],\n",
       "       dtype=torch.uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 顯示第1張圖片內含值\n",
    "train_ds.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000001111111111110000',\n",
       " '0000000011111111111111110000',\n",
       " '0000000111111111111111100000',\n",
       " '0000000111111111110000000000',\n",
       " '0000000011111110110000000000',\n",
       " '0000000001111100000000000000',\n",
       " '0000000000011110000000000000',\n",
       " '0000000000011110000000000000',\n",
       " '0000000000001111110000000000',\n",
       " '0000000000000111111000000000',\n",
       " '0000000000000011111100000000',\n",
       " '0000000000000001111100000000',\n",
       " '0000000000000000011110000000',\n",
       " '0000000000000011111110000000',\n",
       " '0000000000001111111100000000',\n",
       " '0000000000111111111000000000',\n",
       " '0000000011111111110000000000',\n",
       " '0000001111111111000000000000',\n",
       " '0000111111111100000000000000',\n",
       " '0000111111110000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 將非0的數字轉為1，顯示第1張圖片\n",
    "data = train_ds.data[0].clone()\n",
    "data[data>0]=1\n",
    "data = data.numpy()\n",
    "\n",
    "# 將轉換後二維內容顯示出來，隱約可以看出數字為 5\n",
    "text_image=[]\n",
    "for i in range(data.shape[0]):\n",
    "    text_image.append(''.join(data[i].astype(str)))\n",
    "text_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000001111100000000',\n",
       " '0000000000000011111100000000',\n",
       " '0000000000000111111111000000',\n",
       " '0000000000011111111111000000',\n",
       " '0000000000011111111111000000',\n",
       " '0000000000111111111111000000',\n",
       " '0000000001111111110011100000',\n",
       " '0000000011111100000011100000',\n",
       " '0000000111111100000011100000',\n",
       " '0000000111100000000011100000',\n",
       " '0000000111000000000011100000',\n",
       " '0000001111000000000011100000',\n",
       " '0000001111000000001111100000',\n",
       " '0000001110000000011111000000',\n",
       " '0000001110000000111100000000',\n",
       " '0000001110000001111000000000',\n",
       " '0000001111111111111000000000',\n",
       " '0000001111111111100000000000',\n",
       " '0000001111111110000000000000',\n",
       " '0000000111111100000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000',\n",
       " '0000000000000000000000000000']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 將非0的數字轉為1，顯示第2張圖片\n",
    "data = train_ds.data[1].clone()\n",
    "data[data>0]=1\n",
    "data = data.numpy()\n",
    "\n",
    "# 將轉換後二維內容顯示出來，隱約可以看出數字為 5\n",
    "text_image=[]\n",
    "for i in range(data.shape[0]):\n",
    "    text_image.append(''.join(data[i].astype(str)))\n",
    "text_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 顯示第1張圖片圖像\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 第一筆資料\n",
    "X = train_ds.data[0]\n",
    "\n",
    "# 繪製點陣圖，cmap='gray':灰階\n",
    "plt.imshow(X.reshape(28,28), cmap='gray')\n",
    "\n",
    "# 隱藏刻度\n",
    "plt.axis('off') \n",
    "\n",
    "# 顯示圖形\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟3：特徵工程，此步驟無需進行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ds.data = train_ds.data / 255.0\n",
    "# test_ds.data = test_ds.data / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟4：資料分割，此步驟無需進行，載入MNIST資料時，已經切割好了"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟5：建立模型結構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立模型\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(28 * 28, 256), \n",
    "    torch.nn.Dropout(0.2),\n",
    "    torch.nn.Linear(256, 10), \n",
    "    # 使用nn.CrossEntropyLoss()時，不需要將輸出經過softmax層，否則計算的損失會有誤\n",
    "    # torch.nn.Softmax(dim=1)\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟6：結合訓練資料及模型，進行模型訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: [ 6000 / 60000]  Accuracy: 34.45%,  Loss: 2.065308\n",
      "Epoch 1: [12000 / 60000]  Accuracy: 64.72%,  Loss: 1.831411\n",
      "Epoch 1: [18000 / 60000]  Accuracy: 69.43%,  Loss: 1.661156\n",
      "Epoch 1: [24000 / 60000]  Accuracy: 75.77%,  Loss: 1.383004\n",
      "Epoch 1: [30000 / 60000]  Accuracy: 78.65%,  Loss: 1.230076\n",
      "Epoch 1: [36000 / 60000]  Accuracy: 79.70%,  Loss: 1.034142\n",
      "Epoch 1: [42000 / 60000]  Accuracy: 81.32%,  Loss: 1.011110\n",
      "Epoch 1: [48000 / 60000]  Accuracy: 81.28%,  Loss: 0.841987\n",
      "Epoch 1: [54000 / 60000]  Accuracy: 82.08%,  Loss: 0.766128\n",
      "Epoch 1: [60000 / 60000]  Accuracy: 87.32%,  Loss: 0.602637\n",
      "Epoch 2: [ 6000 / 60000]  Accuracy: 84.85%,  Loss: 0.622174\n",
      "Epoch 2: [12000 / 60000]  Accuracy: 85.02%,  Loss: 0.695614\n",
      "Epoch 2: [18000 / 60000]  Accuracy: 82.60%,  Loss: 0.698461\n",
      "Epoch 2: [24000 / 60000]  Accuracy: 86.52%,  Loss: 0.590122\n",
      "Epoch 2: [30000 / 60000]  Accuracy: 86.20%,  Loss: 0.630052\n",
      "Epoch 2: [36000 / 60000]  Accuracy: 85.77%,  Loss: 0.512342\n",
      "Epoch 2: [42000 / 60000]  Accuracy: 86.35%,  Loss: 0.573726\n",
      "Epoch 2: [48000 / 60000]  Accuracy: 85.97%,  Loss: 0.526710\n",
      "Epoch 2: [54000 / 60000]  Accuracy: 86.32%,  Loss: 0.484404\n",
      "Epoch 2: [60000 / 60000]  Accuracy: 89.77%,  Loss: 0.385310\n",
      "Epoch 3: [ 6000 / 60000]  Accuracy: 88.50%,  Loss: 0.414719\n",
      "Epoch 3: [12000 / 60000]  Accuracy: 88.07%,  Loss: 0.524067\n",
      "Epoch 3: [18000 / 60000]  Accuracy: 85.55%,  Loss: 0.529343\n",
      "Epoch 3: [24000 / 60000]  Accuracy: 88.68%,  Loss: 0.455316\n",
      "Epoch 3: [30000 / 60000]  Accuracy: 87.88%,  Loss: 0.506003\n",
      "Epoch 3: [36000 / 60000]  Accuracy: 87.55%,  Loss: 0.404826\n",
      "Epoch 3: [42000 / 60000]  Accuracy: 88.15%,  Loss: 0.468077\n",
      "Epoch 3: [48000 / 60000]  Accuracy: 87.67%,  Loss: 0.438433\n",
      "Epoch 3: [54000 / 60000]  Accuracy: 87.82%,  Loss: 0.410556\n",
      "Epoch 3: [60000 / 60000]  Accuracy: 90.92%,  Loss: 0.327215\n",
      "Epoch 4: [ 6000 / 60000]  Accuracy: 89.50%,  Loss: 0.364054\n",
      "Epoch 4: [12000 / 60000]  Accuracy: 88.95%,  Loss: 0.476826\n",
      "Epoch 4: [18000 / 60000]  Accuracy: 87.10%,  Loss: 0.467418\n",
      "Epoch 4: [24000 / 60000]  Accuracy: 90.27%,  Loss: 0.403539\n",
      "Epoch 4: [30000 / 60000]  Accuracy: 88.77%,  Loss: 0.455361\n",
      "Epoch 4: [36000 / 60000]  Accuracy: 88.35%,  Loss: 0.354975\n",
      "Epoch 4: [42000 / 60000]  Accuracy: 88.80%,  Loss: 0.420847\n",
      "Epoch 4: [48000 / 60000]  Accuracy: 88.28%,  Loss: 0.414282\n",
      "Epoch 4: [54000 / 60000]  Accuracy: 88.75%,  Loss: 0.378674\n",
      "Epoch 4: [60000 / 60000]  Accuracy: 91.53%,  Loss: 0.306363\n",
      "Epoch 5: [ 6000 / 60000]  Accuracy: 89.82%,  Loss: 0.321913\n",
      "Epoch 5: [12000 / 60000]  Accuracy: 89.72%,  Loss: 0.446416\n",
      "Epoch 5: [18000 / 60000]  Accuracy: 87.58%,  Loss: 0.432315\n",
      "Epoch 5: [24000 / 60000]  Accuracy: 90.55%,  Loss: 0.380304\n",
      "Epoch 5: [30000 / 60000]  Accuracy: 89.32%,  Loss: 0.427605\n",
      "Epoch 5: [36000 / 60000]  Accuracy: 88.92%,  Loss: 0.324890\n",
      "Epoch 5: [42000 / 60000]  Accuracy: 89.63%,  Loss: 0.396428\n",
      "Epoch 5: [48000 / 60000]  Accuracy: 88.75%,  Loss: 0.387005\n",
      "Epoch 5: [54000 / 60000]  Accuracy: 89.18%,  Loss: 0.355731\n",
      "Epoch 5: [60000 / 60000]  Accuracy: 91.57%,  Loss: 0.296802\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "lr=0.1\n",
    "\n",
    "# 建立 DataLoader\n",
    "train_loader = DataLoader(train_ds, batch_size=600)\n",
    "\n",
    "# 設定優化器(optimizer)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer = torch.optim.Adadelta(model.parameters(), lr=lr)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "model.train()\n",
    "loss_list = []    \n",
    "correct = y_count = 0\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # if batch_idx == 0 and epoch == 1: print(data.shape)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        \n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        # 正確筆數\n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "        y_count += pred.shape[0]\n",
    "        \n",
    "        # if batch_idx == 0 and epoch == 1: print(output.shape, target.shape)\n",
    "        loss = criterion(output, target)\n",
    "        loss_list.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (batch_idx+1) % 10 == 0:\n",
    "            acc = correct / y_count\n",
    "            correct = y_count = 0\n",
    "            batch = (batch_idx+1) * len(data)\n",
    "            data_count = len(train_loader.dataset)\n",
    "            print(f'Epoch {epoch + 1}: [{batch:5d} / {data_count}]' +\n",
    "                  f'  Accuracy: {acc*100:.2f}%,  Loss: {loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CrossEntropyLoss 可接納 output, target 維度不同，[600, 10]及[600]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 對訓練過程的損失繪圖"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2087d3c9910>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_list, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟7：評分(Score Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "平均損失: 0.3356, 準確率: 9052/10000 (91%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 建立 DataLoader\n",
    "test_loader = DataLoader(test_ds, shuffle=False, batch_size=test_ds.targets.shape[0])\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "for data, target in test_loader:\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    output = model(data)\n",
    "\n",
    "    # sum up batch loss\n",
    "    test_loss += criterion(output, target).item()\n",
    "\n",
    "    # 預測\n",
    "    pred = output.argmax(dim=1, keepdim=True)  \n",
    "\n",
    "    # 正確筆數\n",
    "    correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "# 顯示測試結果\n",
    "batch = batch_idx * len(data)\n",
    "data_count = len(test_loader.dataset)\n",
    "percentage = 100. * correct / data_count\n",
    "print(f'平均損失: {test_loss:.4f}, 準確率: {correct}/{data_count}' + \n",
    "      f' ({percentage:.0f}%)\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用 torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchmetrics in c:\\anaconda3\\lib\\site-packages (0.7.2)\n",
      "Requirement already satisfied: packaging in c:\\anaconda3\\lib\\site-packages (from torchmetrics) (21.3)\n",
      "Requirement already satisfied: pyDeprecate==0.3.* in c:\\anaconda3\\lib\\site-packages (from torchmetrics) (0.3.2)\n",
      "Requirement already satisfied: numpy>=1.17.2 in c:\\anaconda3\\lib\\site-packages (from torchmetrics) (1.23.5)\n",
      "Requirement already satisfied: torch>=1.3.1 in c:\\anaconda3\\lib\\site-packages (from torchmetrics) (1.13.0+cu117)\n",
      "Requirement already satisfied: typing-extensions in c:\\anaconda3\\lib\\site-packages (from torch>=1.3.1->torchmetrics) (4.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\anaconda3\\lib\\site-packages (from packaging->torchmetrics) (2.4.7)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9052, device='cuda:0')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchmetrics\n",
    "\n",
    "torchmetrics.functional.accuracy(pred.reshape(-1), test_ds.targets.to(device)\n",
    "                                 , num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 實際比對測試資料的前20筆"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "實際值: 7 2 1 0 4 1 4 9 5 9 0 6 9 0 1 5 9 7 3 4\n",
      "預測值: 7 2 1 0 4 1 4 9 6 9 0 6 9 0 1 5 9 7 3 4\n"
     ]
    }
   ],
   "source": [
    "# 實際預測 20 筆資料\n",
    "test_loader = DataLoader(test_ds, shuffle=False, batch_size=20)\n",
    "for data, target in test_loader:\n",
    "    data = data.to(device)\n",
    "    pred = model(data)\n",
    "    output = pred.argmax(dim=1, keepdim=True)\n",
    "    predictions = output.cpu().numpy()\n",
    "    break\n",
    "    \n",
    "# 比對\n",
    "print('實際值:', ' '.join(target.numpy().astype(str)))\n",
    "print('預測值:', ' '.join(predictions.astype(str).reshape(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "預測機率: [[0.01 0.   0.04 0.   0.03 0.01 0.9  0.   0.01 0.  ]]\n",
      "預測類別: 6\n"
     ]
    }
   ],
   "source": [
    "# 顯示第 9 筆的機率\n",
    "import numpy as np\n",
    "\n",
    "i=8\n",
    "data = test_ds[i][0]\n",
    "data = data.reshape(1, *data.shape).to(device)\n",
    "#print(data.shape)\n",
    "predictions = torch.softmax(model(data), dim=1)\n",
    "print(f'預測機率: {np.around(predictions.detach().cpu().numpy(), 2)}')\n",
    "print(f'預測類別: {model(data).argmax(dim=1).item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 顯示第 9 筆圖像\n",
    "X2 = test_ds[i][0]\n",
    "plt.imshow(X2.reshape(28,28), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟8：評估，暫不進行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟9：模型佈署"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型存檔\n",
    "torch.save(model, 'model.pt')\n",
    "\n",
    "# 模型載入\n",
    "model = torch.load('model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 權重存檔\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "# 權重載入\n",
    "model.load_state_dict(torch.load('model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "每一層的 state_dict:\n",
      "1.weight \t torch.Size([256, 784])\n",
      "1.bias \t torch.Size([256])\n",
      "3.weight \t torch.Size([10, 256])\n",
      "3.bias \t torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "# 顯示每一層的 state_dict 維度\n",
    "print(\"每一層的 state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 步驟10：新資料預測"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual/prediction: 0 0\n",
      "actual/prediction: 1 1\n",
      "actual/prediction: 2 2\n",
      "actual/prediction: 3 0\n",
      "actual/prediction: 4 4\n",
      "actual/prediction: 5 5\n",
      "actual/prediction: 6 6\n",
      "actual/prediction: 7 3\n",
      "actual/prediction: 8 8\n",
      "actual/prediction: 9 8\n"
     ]
    }
   ],
   "source": [
    "# 使用小畫家，繪製 0~9，實際測試看看\n",
    "from PIL import Image\n",
    "\n",
    "# 讀取影像並轉為單色\n",
    "# image to a Torch tensor\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize([28, 28]),\n",
    "    transforms.PILToTensor()\n",
    "])\n",
    "for i in range(10):\n",
    "    uploaded_file = f'./myDigits/{i}.png'\n",
    "    image = Image.open(uploaded_file)\n",
    "    X1 = transform(image)\n",
    "    X1 = torch.FloatTensor(255.0-X1).to(device)\n",
    "    print(f'actual/prediction: {i} {model(X1).argmax(dim=1).item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 其他：顯示模型彙總資訊(summary)、繪製圖形顯示模型結構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 顯示模型的彙總資訊\n",
    "for name, module in model.named_children():\n",
    "    print(f'{name}: {module}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchinfo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "summary(model, (60000, 28, 28)) # input dimension size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch 無法繪製模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
